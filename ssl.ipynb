{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-supervised learning project\n",
    "Comparing self-supervised ResNet with SimCLR to normal ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal settings and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.transforms import SimCLRTransform, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    # Should increase performance on GPUs with tensor cores \n",
    "    # Not sure if it is supported on all GPUs; consider disabling\n",
    "    torch.set_float32_matmul_precision('medium') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 32 # I have 32 CPU threads\n",
    "input_size = 32 # CIFAR10 images are 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prints some metrics we can use to compare the different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def eval_classifier(classifier):\n",
    "    classifier.to(device)  \n",
    "\n",
    "    classifier.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_classifier_dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = classifier(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same classifier is used for the SimCLR model and the pretrained ResNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from lightly.models.utils import deactivate_requires_grad\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, backbone, num_ftrs):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "        # freeze the backbone\n",
    "        deactivate_requires_grad(backbone)\n",
    "\n",
    "        self.fc = nn.Linear(num_ftrs, 10) # 10 is the number of output classes\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_hat = self.backbone(x).flatten(start_dim=1)\n",
    "        y_hat = self.fc(y_hat)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss_fc\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.custom_histogram_weights()\n",
    "\n",
    "    def custom_histogram_weights(self):\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat = torch.nn.functional.softmax(y_hat, dim=1)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        num = predicted.shape[0]\n",
    "        correct = (predicted == y).float().sum()\n",
    "        self.validation_step_outputs.append((num, correct))\n",
    "        return num, correct\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.validation_step_outputs:\n",
    "            total_num = 0\n",
    "            total_correct = 0\n",
    "            for num, correct in self.validation_step_outputs:\n",
    "                total_num += num\n",
    "                total_correct += correct\n",
    "            acc = total_correct / total_num\n",
    "            self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "            self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.fc.parameters(), lr=2e-2)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same dataset is used to fine-tune the classifier using the SimCLR model and the pretrained ResNet model.\n",
    "\n",
    "We use just 1% of the labeled CIFAR10 dataset (500 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_classifier_ds_full = torchvision.datasets.CIFAR10(\n",
    "    root=\"datasets/cifar10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_classifier_ds = torchvision.datasets.CIFAR10(\n",
    "    root=\"datasets/cifar10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Selecting 1% of the training data\n",
    "num_train_samples = len(train_classifier_ds_full)\n",
    "subset_size = int(0.01 * num_train_samples)\n",
    "indices = np.random.choice(num_train_samples, subset_size, replace=False)\n",
    "train_classifier_ds = Subset(train_classifier_ds_full, indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_classifier_dl = DataLoader(\n",
    "    train_classifier_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "train_classifier_dl_full = DataLoader(\n",
    "    train_classifier_ds_full,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_classifier_dl = DataLoader(\n",
    "    test_classifier_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining ResNet with SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_batch_size = 4096 # Used by the original SimCLR (https://github.com/google-research/simclr?tab=readme-ov-file#pretraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = SimCLRTransform(input_size=input_size, vf_prob=0.5, rr_prob=0.5)\n",
    "\n",
    "test_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_simclr_ds = torchvision.datasets.CIFAR10(\n",
    "    \"datasets/cifar10\", download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_simclr_ds = torchvision.datasets.CIFAR10(\n",
    "    \"datasets/cifar10\", download=True, transform=test_transform\n",
    ")\n",
    "\n",
    "train_simclr_dl = torch.utils.data.DataLoader(\n",
    "    train_simclr_ds,\n",
    "    batch_size=simclr_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "test_simclr_dl = torch.utils.data.DataLoader(\n",
    "    test_simclr_ds,\n",
    "    batch_size=simclr_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "\n",
    "# Inspired by\n",
    "# https://docs.lightly.ai/self-supervised-learning/tutorials/package/tutorial_simclr_clothing.html#create-the-simclr-model \n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n",
    "\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model = SimCLRModel()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\", log_every_n_steps=1)\n",
    "trainer.fit(simclr_model, train_simclr_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simclr_model.state_dict(), \"models/pretrained-simclr-1000.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance (qualitative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lightly docs included some instructions on how to visualize the nearest neighbors of a couple of images, so let's take a look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Borrowed from\n",
    "# https://docs.lightly.ai/self-supervised-learning/tutorials/package/tutorial_simclr_clothing.html#create-the-simclr-model \n",
    "def generate_embeddings(model, dataloader):\n",
    "    \"\"\"Generates representations for all images in the dataloader with the given model\"\"\"\n",
    "\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for img, _ in dataloader:  # Only extract the images, ignore the labels\n",
    "            img = img.to(model.device)\n",
    "            emb = model.backbone(img).flatten(start_dim=1)\n",
    "            embeddings.append(emb)\n",
    "\n",
    "    embeddings = torch.cat(embeddings, 0)\n",
    "    embeddings = normalize(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "def plot_knn_examples(embeddings, images, n_neighbors=3, num_examples=6):\n",
    "    \"\"\"Plots multiple rows of random images with their nearest neighbors.\"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "    samples_idx = np.random.choice(len(indices), size=num_examples, replace=False)\n",
    "\n",
    "    for idx in samples_idx:\n",
    "        fig = plt.figure(figsize=(15, 3))\n",
    "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
    "            ax = fig.add_subplot(1, n_neighbors, plot_x_offset + 1)\n",
    "            plt.imshow(images[neighbor_idx])\n",
    "            ax.set_title(f\"d={distances[idx][plot_x_offset]:.3f}\")\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR10 dataset is stored as binary files using pickle, so we need to unpickle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def load_cifar10_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def unpack_image(data):\n",
    "    \"\"\" Convert a CIFAR-10 flattened image to a 32x32x3 numpy array. \"\"\"\n",
    "    # Reshape the array to 3x32x32 and then transpose it to 32x32x3\n",
    "    r = data[:1024].reshape(32, 32)\n",
    "    g = data[1024:2048].reshape(32, 32)\n",
    "    b = data[2048:].reshape(32, 32)\n",
    "    return np.stack((r, g, b), axis=-1)\n",
    "\n",
    "images = []\n",
    "batches = [f\"data_batch_{i}\" for i in range(1, 6)]\n",
    "for batch_file in batches:\n",
    "    batch = load_cifar10_batch(Path(\"datasets/cifar10/cifar-10-batches-py\") / batch_file)\n",
    "    # Extract images and labels\n",
    "    data = batch[b'data']\n",
    "    labels = batch[b'labels']\n",
    "\n",
    "    batch_images = [unpack_image(data[i]) for i in range(len(data))]\n",
    "    images.extend(batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "simclr_model = SimCLRModel()\n",
    "simclr_model.load_state_dict(torch.load(\"models/pretrained-simclr.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_model.eval() # Enable eval mode for better inference \n",
    "embeddings = generate_embeddings(simclr_model, test_simclr_dl)\n",
    "plot_knn_examples(embeddings, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning SimCLR model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "simclr_model = SimCLRModel()\n",
    "simclr_model.load_state_dict(torch.load(\"models/pretrained-simclr.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping prevents overfitting by stopping the training process once validation loss stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',   \n",
    "    patience=10,           \n",
    "    verbose=True,          \n",
    "    mode='min'             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_classifier = Classifier(simclr_model.backbone, num_ftrs=512) # 512 = resnet.fc.in_features\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\", log_every_n_steps=1, callbacks=[early_stop_callback])\n",
    "trainer.fit(simclr_classifier, train_classifier_dl, test_classifier_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simclr_classifier.state_dict(), \"models/fine-tuned-simclr.cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr_classifier.eval()\n",
    "eval_classifier(simclr_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning non-SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The early stopping callback needs to be reset to train the other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',   \n",
    "    patience=10,           \n",
    "    verbose=True,          \n",
    "    mode='min'             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_classifier = Classifier(pretrained_resnet, num_ftrs=1000) # For some reason, this needs to be 1000 for this model\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\", log_every_n_steps=1, callbacks=[early_stop_callback])\n",
    "trainer.fit(pt_classifier, train_classifier_dl, test_classifier_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pt_classifier.state_dict(), \"models/fine-tuned-imagenet.cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classifier(pt_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
